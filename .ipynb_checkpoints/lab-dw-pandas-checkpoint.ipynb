{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {},
   "source": [
    "# Lab | Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1973e9e-8be6-4039-b70e-d73ee0d94c99",
   "metadata": {},
   "source": [
    "In this lab, we will be working with the customer data from an insurance company, which can be found in the CSV file located at the following link: https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "The data includes information such as customer ID, state, gender, education, income, and other variables that can be used to perform various analyses.\n",
    "\n",
    "Throughout the lab, we will be using the pandas library in Python to manipulate and analyze the data. Pandas is a powerful library that provides various data manipulation and analysis tools, including the ability to load and manipulate data from a variety of sources, including CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045146f-f4f7-44d9-8cd9-130d6400c73a",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "- Customer - Customer ID\n",
    "\n",
    "- ST - State where customers live\n",
    "\n",
    "- Gender - Gender of the customer\n",
    "\n",
    "- Education - Background education of customers \n",
    "\n",
    "- Customer Lifetime Value - Customer lifetime value(CLV) is the total revenue the client will derive from their entire relationship with a customer. In other words, is the predicted or calculated value of a customer over their entire duration as a policyholder with the insurance company. It is an estimation of the net profit that the insurance company expects to generate from a customer throughout their relationship with the company. Customer Lifetime Value takes into account factors such as the duration of the customer's policy, premium payments, claim history, renewal likelihood, and potential additional services or products the customer may purchase. It helps insurers assess the long-term profitability and value associated with retaining a particular customer.\n",
    "\n",
    "- Income - Customers income\n",
    "\n",
    "- Monthly Premium Auto - Amount of money the customer pays on a monthly basis as a premium for their auto insurance coverage. It represents the recurring cost that the insured person must pay to maintain their insurance policy and receive coverage for potential damages, accidents, or other covered events related to their vehicle.\n",
    "\n",
    "- Number of Open Complaints - Number of complaints the customer opened\n",
    "\n",
    "- Policy Type - There are three type of policies in car insurance (Corporate Auto, Personal Auto, and Special Auto)\n",
    "\n",
    "- Vehicle Class - Type of vehicle classes that customers have Two-Door Car, Four-Door Car SUV, Luxury SUV, Sports Car, and Luxury Car\n",
    "\n",
    "- Total Claim Amount - the sum of all claims made by the customer. It represents the total monetary value of all approved claims for incidents such as accidents, theft, vandalism, or other covered events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72419b-20fc-4905-817a-8c83abc59de6",
   "metadata": {},
   "source": [
    "External Resources: https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ece17-e919-4e23-96c0-c7c59778436a",
   "metadata": {},
   "source": [
    "## Challenge 1: Understanding the data\n",
    "\n",
    "In this challenge, you will use pandas to explore a given dataset. Your task is to gain a deep understanding of the data by analyzing its characteristics, dimensions, and statistical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91437bd5-59a6-49c0-8150-ef0e6e6eb253",
   "metadata": {},
   "source": [
    "- Identify the dimensions of the dataset by determining the number of rows and columns it contains.\n",
    "- Determine the data types of each column and evaluate whether they are appropriate for the nature of the variable. You should also provide suggestions for fixing any incorrect data types.\n",
    "- Identify the number of unique values for each column and determine which columns appear to be categorical. You should also describe the unique values of each categorical column and the range of values for numerical columns, and give your insights.\n",
    "- Compute summary statistics such as mean, median, mode, standard deviation, and quartiles to understand the central tendency and distribution of the data for numerical columns. You should also provide your conclusions based on these summary statistics.\n",
    "- Compute summary statistics for categorical columns and providing your conclusions based on these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd4e8cd8-a6f6-486c-a5c4-1745b0c035f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4008 entries, 0 to 4007\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Customer                   1071 non-null   object \n",
      " 1   ST                         1071 non-null   object \n",
      " 2   GENDER                     954 non-null    object \n",
      " 3   Education                  1071 non-null   object \n",
      " 4   Customer Lifetime Value    1068 non-null   object \n",
      " 5   Income                     1071 non-null   float64\n",
      " 6   Monthly Premium Auto       1071 non-null   float64\n",
      " 7   Number of Open Complaints  1071 non-null   object \n",
      " 8   Policy Type                1071 non-null   object \n",
      " 9   Vehicle Class              1071 non-null   object \n",
      " 10  Total Claim Amount         1071 non-null   float64\n",
      "dtypes: float64(3), object(8)\n",
      "memory usage: 344.6+ KB\n",
      "Customer                     1071\n",
      "ST                              8\n",
      "GENDER                          5\n",
      "Education                       6\n",
      "Customer Lifetime Value      1027\n",
      "Income                        774\n",
      "Monthly Premium Auto          132\n",
      "Number of Open Complaints       6\n",
      "Policy Type                     3\n",
      "Vehicle Class                   6\n",
      "Total Claim Amount            761\n",
      "dtype: int64\n",
      "Categorische kolommen: ['ST', 'GENDER', 'Education', 'Number of Open Complaints', 'Policy Type', 'Vehicle Class']\n",
      "Numerieke kolommen: ['Customer', 'Customer Lifetime Value', 'Income', 'Monthly Premium Auto', 'Total Claim Amount']\n",
      "\n",
      "Mediaan per kolom:\n",
      " Income                  36234.000000\n",
      "Monthly Premium Auto       83.000000\n",
      "Total Claim Amount        354.729129\n",
      "dtype: float64\n",
      "\n",
      "Modus per kolom:\n",
      " Income                    0.0\n",
      "Monthly Premium Auto     65.0\n",
      "Total Claim Amount      321.6\n",
      "Name: 0, dtype: float64\n",
      "            ST GENDER Education Number of Open Complaints    Policy Type  \\\n",
      "count     1071    954      1071                      1071           1071   \n",
      "unique       8      5         6                         6              3   \n",
      "top     Oregon      F  Bachelor                    1/0/00  Personal Auto   \n",
      "freq       320    457       324                       830            780   \n",
      "\n",
      "        Vehicle Class  \n",
      "count            1071  \n",
      "unique              6  \n",
      "top     Four-Door Car  \n",
      "freq              576  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/noachmeged/Downloads/file1.csv')\n",
    "# - Identify the dimensions of the dataset by determining the number of rows and columns it contains.\n",
    "df.shape\n",
    "# - Determine the data types of each column and evaluate whether they are appropriate for the nature of the variable.\n",
    "# State, Gender,Education should be a string because these are names. Removing any typos or numbers in the column should make it a string \n",
    "# Customer Lifetime Value should be a float and should only contain percentages. Removing the NaNs and letter and converting it into a string should fix the columns\n",
    "# Number of Open Complaints( is now a date ), Policy Type, Vehicle Class should are all integer in the because they are hiÃ«rarical. \n",
    "\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# - Identify the number of unique values for each column\n",
    "unique_values = df.nunique()\n",
    "print(unique_values)\n",
    "# Determine which columns appear to be categorical. \n",
    "# You should also describe the unique values of each categorical column and the range of values for numerical columns, and give your insights.\n",
    "\n",
    "# Definieer categorische en numerieke kolommen op basis van aantal unieke waarden\n",
    "categorical_columns = [col for col in df.columns if df[col].nunique() < 15]\n",
    "numerical_columns = [col for col in df.columns if df[col].nunique() >= 15]\n",
    "\n",
    "print(\"Categorische kolommen:\", categorical_columns)\n",
    "print(\"Numerieke kolommen:\", numerical_columns)\n",
    "\n",
    "\n",
    "# Compute summary statistics such as mean, median, mode, standard deviation, \n",
    "# and quartiles to understand the central tendency and distribution of the data for numerical columns. \n",
    "# You should also provide your conclusions based on these summary statistics.\n",
    "\n",
    "\n",
    "median_values = df.median(numeric_only=True)\n",
    "print(\"\\nMediaan per kolom:\\n\", median_values)\n",
    "\n",
    "mode_values = df.mode(numeric_only=True).iloc[0]  \n",
    "print(\"\\nModus per kolom:\\n\", mode_values)\n",
    "df.describe().round()\n",
    "\n",
    "df.describe()\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = [col for col in df.columns if df[col].nunique() < 15]  # Replace with the actual categorical column names in your dataset\n",
    "\n",
    "# Compute summary statistics for categorical columns\n",
    "categorical_summary = df[categorical_columns].describe()\n",
    "print(categorical_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4a35c",
   "metadata": {},
   "source": [
    "Based on the provided summary statistics for the columns Income, Monthly Premium Auto, and Total Claim Amount, we can draw insights about central tendency, spread, and possible outliers.\n",
    "\n",
    "Analysis of the Summary Statistics\n",
    "Income:\n",
    "\n",
    "Mean: The average income is approximately 39,296.\n",
    "Standard Deviation: The standard deviation is 30,469, indicating a wide range of incomes in this dataset.\n",
    "Minimum and Maximum: The minimum income is 0, and the maximum is 99,960, reflecting a broad range, with some individuals possibly having low or zero income.\n",
    "Quartiles:\n",
    "The 25th percentile is around 14,072, and the 75th percentile is around 64,631.\n",
    "This spread suggests that half of the incomes lie between 14,072 and 64,631.\n",
    "Conclusion: Income shows a broad range, with some low values (minimum is 0) pointing to a diverse income distribution. The high standard deviation suggests that some individuals have incomes well above or below the average.\n",
    "Monthly Premium Auto:\n",
    "\n",
    "Mean: The average auto premium is 193, which appears quite high relative to the quartiles.\n",
    "Standard Deviation: An extremely high standard deviation of 1,601 indicates a few extreme outliers.\n",
    "Minimum and Maximum: Premiums range from a minimum of 61 to a maximum of 35,354, which is unusually high and likely indicates an outlier or data error.\n",
    "Quartiles:\n",
    "The 25th percentile is 68, the 50th percentile (median) is 83, and the 75th percentile is 109.5, suggesting that most values are quite low, contrasting sharply with the mean.\n",
    "Conclusion: The Monthly Premium Auto column likely contains outliers, as seen by the unusual maximum value and high standard deviation. The median and quartiles suggest that most values are much lower than the mean, indicating that the higher values are not representative of the majority.\n",
    "Total Claim Amount:\n",
    "\n",
    "Mean: The average claim amount is 404.99.\n",
    "Standard Deviation: The standard deviation is 293, indicating a reasonable spread but not as extreme as the premium column.\n",
    "Minimum and Maximum: Claim amounts range from a minimum of 0.38 to a maximum of 2,893.24, suggesting some claims are very small, while others are significantly larger.\n",
    "Quartiles:\n",
    "The 25th percentile is 202.16, the median is 354.73, and the 75th percentile is 532.80.\n",
    "Values are relatively evenly distributed around the median without large differences like those in the premium column.\n",
    "Conclusion: Claim amounts have a normal distribution, without extreme outliers like the premium column. The quartiles and standard deviation indicate that most claim amounts fall within a reasonable range.\n",
    "General Conclusions\n",
    "Outliers: The Monthly Premium Auto column includes some exceptionally high values, likely indicating data errors or rare cases. These outliers should be further examined.\n",
    "Spread and Central Tendency:\n",
    "Income and Total Claim Amount exhibit a normal range of values with a broad spread.\n",
    "The difference between mean and median for Income suggests a skewed distribution, with some higher-income values.\n",
    "Data Quality Check: It would be helpful to investigate the high values in Monthly Premium Auto, as these may impact analyses.\n",
    "With these insights, you can decide to handle or adjust outliers depending on the goals of your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a703890-63db-4944-b7ab-95a4f8185120",
   "metadata": {},
   "source": [
    "## Challenge 2: analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776a403-c56a-452f-ac33-5fd4fdb06fc7",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbc484-da4d-4f9c-9343-e1d44311a87e",
   "metadata": {},
   "source": [
    "The marketing team wants to know the top 5 less common customer locations. Create a pandas Series object that contains the customer locations and their frequencies, and then retrieve the top 5 less common locations in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dca5073-4520-4f42-9390-4b92733284ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST\n",
      "Nevada         98\n",
      "Washington    111\n",
      "Arizona       211\n",
      "Oregon        320\n",
      "California    331\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Abbreviations and their full names\n",
    "state_mapping = {'AZ': 'Arizona', 'WA': 'Washington', 'Cali': 'California'}\n",
    "\n",
    "# Clean the 'state' column\n",
    "df['ST'] = df['ST'].replace(state_mapping).str.strip()\n",
    "\n",
    "# Get top 5 least common states\n",
    "top_5_less_common = df['ST'].value_counts().sort_values().head(5)\n",
    "\n",
    "print(top_5_less_common)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce80f43-4afa-43c7-a78a-c917444da4e0",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The sales team wants to know the total number of policies sold for each type of policy. Create a pandas Series object that contains the policy types and their total number of policies sold, and then retrieve the policy type with the highest number of policies sold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f13997-1555-4f98-aca6-970fda1d2c3f",
   "metadata": {},
   "source": [
    "*Hint:*\n",
    "- *Using value_counts() method simplifies this analysis.*\n",
    "- *Futhermore, there is a method that returns the index of the maximum value in a column or row.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcfad6c1-9af2-4b0b-9aa9-0dc5c17473c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of policies sold per policy type:\n",
      "Policy Type\n",
      "Personal Auto     780\n",
      "Corporate Auto    234\n",
      "Special Auto       57\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Policy type with the highest number of policies sold:\n",
      "Personal Auto\n"
     ]
    }
   ],
   "source": [
    "# Get the count of each policy type\n",
    "policy_counts = df['Policy Type'].value_counts()\n",
    "\n",
    "# Retrieve the policy type with the highest number of policies sold\n",
    "top_policy_type = policy_counts.idxmax()\n",
    "\n",
    "print(\"Total number of policies sold per policy type:\")\n",
    "print(policy_counts)\n",
    "\n",
    "print(\"\\nPolicy type with the highest number of policies sold:\")\n",
    "print(top_policy_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b863fd3-bf91-4d5d-86eb-be29ed9f5b70",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The sales team wants to know if customers with Personal Auto have a lower income than those with Corporate Auto. How does the average income compare between the two policy types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1386d75-2810-4aa1-93e0-9485aa12d552",
   "metadata": {},
   "source": [
    "- Use *loc* to create two dataframes: one containing only Personal Auto policies and one containing only Corporate Auto policies.\n",
    "- Calculate the average income for each policy.\n",
    "- Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c0563cf-6f8b-463d-a321-651a972f82e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average income for Personal Auto policies: 38180.69871794872\n",
      "Average income for Corporate Auto policies: 41390.31196581197\n"
     ]
    }
   ],
   "source": [
    "# Filter DataFrames for Personal Auto and Corporate Auto policies\n",
    "personal_auto_df = df.loc[df['Policy Type'] == 'Personal Auto']\n",
    "corporate_auto_df = df.loc[df['Policy Type'] == 'Corporate Auto']\n",
    "\n",
    "# Calculate the average income for each policy type\n",
    "avg_income_personal = personal_auto_df['Income'].mean()\n",
    "avg_income_corporate = corporate_auto_df['Income'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(\"Average income for Personal Auto policies:\", avg_income_personal)\n",
    "print(\"Average income for Corporate Auto policies:\", avg_income_corporate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b16c27-f4a5-4727-a229-1f88671cf4e2",
   "metadata": {},
   "source": [
    "### Bonus: Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac584986-299b-475f-ac2e-928c16c3f512",
   "metadata": {},
   "source": [
    "Your goal is to identify customers with a high policy claim amount.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Review again the statistics for total claim amount to gain an understanding of the data.\n",
    "- To identify potential areas for improving customer retention and profitability, we want to focus on customers with a high policy claim amount. Consider customers with a high policy claim amount to be those in the top 25% of the total claim amount. Create a pandas DataFrame object that contains information about customers with a policy claim amount greater than the 75th percentile.\n",
    "- Use DataFrame methods to calculate summary statistics about the high policy claim amount data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3af5f1-6023-4b05-9c01-d05392daa650",
   "metadata": {},
   "source": [
    "*Note: When analyzing data, we often want to focus on certain groups of values to gain insights. Percentiles are a useful tool to help us define these groups. A percentile is a measure that tells us what percentage of values in a dataset are below a certain value. For example, the 75th percentile represents the value below which 75% of the data falls. Similarly, the 25th percentile represents the value below which 25% of the data falls. When we talk about the top 25%, we are referring to the values that fall above the 75th percentile, which represent the top quarter of the data. On the other hand, when we talk about the bottom 25%, we are referring to the values that fall below the 25th percentile, which represent the bottom quarter of the data. By focusing on these groups, we can identify patterns and trends that may be useful for making decisions and taking action.*\n",
    "\n",
    "*Hint: look for a method that gives you the percentile or quantile 0.75 and 0.25 for a Pandas Series.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d234634-50bd-41e0-88f7-d5ba684455d1",
   "metadata": {},
   "source": [
    "*Hint 2: check `Boolean selection according to the values of a single column` in https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731bca6-a760-4860-a27b-a33efa712ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
